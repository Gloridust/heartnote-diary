import { useState, useRef, useCallback, useEffect } from 'react';

export interface VoiceMessage {
  id: number;
  content: string;
  isUser: boolean;
  timestamp: number;
}

export interface VoiceChatState {
  isRecording: boolean;
  isPaused: boolean;
  isConnected: boolean;
  error: string | null;
  isProcessing: boolean;
  messages: VoiceMessage[];
}

export interface VoiceChatActions {
  startRecording: () => Promise<void>;
  stopRecording: () => void;
  pauseSession: () => void;
  resumeSession: () => void;
  endSession: () => Promise<VoiceMessage[]>;
  clearError: () => void;
}

interface ChatMessage {
  role: 'user' | 'assistant';
  content: string;
}

export function useVoiceChat(): VoiceChatState & VoiceChatActions {
  const [isRecording, setIsRecording] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [isConnected, setIsConnected] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [isProcessing, setIsProcessing] = useState(false);
  const [messages, setMessages] = useState<VoiceMessage[]>([]);
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const chatHistoryRef = useRef<ChatMessage[]>([]);

  const clearError = useCallback(() => {
    setError(null);
  }, []);

  const startRecording = useCallback(async () => {
    try {
      setError(null);
      
      // è·å–éº¦å…‹é£æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      });

      // åˆ›å»ºMediaRecorder
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });

      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        console.log('ğŸ›‘ å½•éŸ³å·²åœæ­¢ï¼Œå¼€å§‹å¤„ç†...');
        try {
          await processAudioChunks();
          console.log('âœ… éŸ³é¢‘å¤„ç†å®Œæˆ');
        } catch (error) {
          console.error('âŒ éŸ³é¢‘å¤„ç†é”™è¯¯:', error);
          setError('è¯­éŸ³å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•');
        } finally {
          setIsProcessing(false);
          console.log('ğŸ”„ å¤„ç†çŠ¶æ€å·²é‡ç½®');
        }
      };

      // å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡å¼€å§‹å½•éŸ³ï¼Œæ·»åŠ æ¬¢è¿æ¶ˆæ¯
      if (messages.length === 0) {
        const welcomeMessage: VoiceMessage = {
          id: Date.now(),
          content: 'ä½ å¥½ï¼æˆ‘æ˜¯ä¿¡è¯­ï¼Œä½ çš„AIæ—¥è®°åŠ©æ‰‹ã€‚ä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·ï¼Ÿæœ‰ä»€ä¹ˆæƒ³è¦åˆ†äº«çš„å—ï¼Ÿ',
          isUser: false,
          timestamp: Date.now()
        };
        console.log('ğŸ‘‹ æ·»åŠ æ¬¢è¿æ¶ˆæ¯:', welcomeMessage);
        setMessages([welcomeMessage]);
      } else {
        console.log('ğŸ“ ç»§ç»­ç°æœ‰å¯¹è¯ï¼Œå½“å‰æ¶ˆæ¯æ•°:', messages.length);
      }

      mediaRecorder.start(1000); // æ¯ç§’æ”¶é›†ä¸€æ¬¡æ•°æ®
      setIsRecording(true);
      setIsConnected(true);
      setIsPaused(false);
      
      console.log('ğŸ¤ å½•éŸ³å·²å¼€å§‹ï¼Œå½“å‰æ¶ˆæ¯æ•°é‡:', messages.length);
      console.log('ğŸ“‹ å½•éŸ³å¼€å§‹æ—¶çš„æ¶ˆæ¯åˆ—è¡¨:', messages);

    } catch (error) {
      console.error('Failed to start recording:', error);
      setError('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®');
    }
  }, []);

  const stopRecording = useCallback(() => {
    console.log('ğŸ”´ å‡†å¤‡åœæ­¢å½•éŸ³...');
    if (mediaRecorderRef.current && isRecording) {
      console.log('â¹ï¸ åœæ­¢å½•éŸ³ä¸­...');
      setIsProcessing(true);
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      
      // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
      console.log('ğŸ¤ éº¦å…‹é£å·²å…³é—­');
    } else {
      console.log('âš ï¸ å½•éŸ³å™¨æœªè¿è¡Œæˆ–ä¸å­˜åœ¨');
    }
  }, [isRecording]);

  const pauseSession = useCallback(() => {
    if (isRecording) {
      stopRecording();
    }
    setIsPaused(true);
  }, [isRecording, stopRecording]);

  const resumeSession = useCallback(async () => {
    if (isPaused) {
      setIsPaused(false);
      await startRecording();
    }
  }, [isPaused, startRecording]);

  const endSession = useCallback(async (): Promise<VoiceMessage[]> => {
    if (isRecording) {
      stopRecording();
    }
    
    setIsConnected(false);
    setIsPaused(false);
    
    const finalMessages = [...messages];
    
    // æ¸…ç†çŠ¶æ€
    setMessages([]);
    chatHistoryRef.current = [];
    
    return finalMessages;
  }, [isRecording, stopRecording]);

  const processAudioChunks = async () => {
    console.log('ğŸ¤ å¼€å§‹å¤„ç†éŸ³é¢‘æ•°æ®...');
    if (audioChunksRef.current.length === 0) {
      console.error('âŒ æ²¡æœ‰å½•åˆ¶åˆ°éŸ³é¢‘æ•°æ®');
      setError('æ²¡æœ‰å½•åˆ¶åˆ°éŸ³é¢‘æ•°æ®');
      return;
    }

    try {
      // 1. å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºblob
      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
      console.log('ğŸ“ éŸ³é¢‘Blobåˆ›å»ºæˆåŠŸ:', audioBlob.size, 'bytes');
      
      // 2. è½¬æ¢ä¸ºbase64
      console.log('ğŸ”„ å¼€å§‹è½¬æ¢ä¸ºbase64...');
      const base64Audio = await blobToBase64(audioBlob);
      console.log('âœ… Base64è½¬æ¢å®Œæˆï¼Œé•¿åº¦:', base64Audio.length);
      
      // 3. ç›´æ¥è°ƒç”¨è¯­éŸ³è½¬æ–‡å­—APIï¼ˆæé€Ÿç‰ˆï¼‰
      console.log('ğŸ—£ï¸ å¼€å§‹è¯­éŸ³è¯†åˆ«...');
      const speechResponse = await fetch('/api/speech-to-text', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          audioData: base64Audio
        })
      });

      if (!speechResponse.ok) {
        console.error('âŒ è¯­éŸ³è¯†åˆ«è¯·æ±‚å¤±è´¥:', speechResponse.status, speechResponse.statusText);
        throw new Error('è¯­éŸ³è¯†åˆ«å¤±è´¥');
      }

      const speechResult = await speechResponse.json();
      console.log('ğŸ“ è¯­éŸ³è¯†åˆ«ç»“æœ:', speechResult);
      
      if (!speechResult.success) {
        console.error('âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥:', speechResult.error);
        throw new Error(speechResult.error || 'è¯­éŸ³è¯†åˆ«å¤±è´¥');
      }

      const userText = speechResult.text;
      console.log('ğŸ‘¤ ç”¨æˆ·è¯´è¯å†…å®¹:', userText);
      
      // 4. æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
      const userMessage: VoiceMessage = {
        id: Date.now(),
        content: userText,
        isUser: true,
        timestamp: Date.now()
      };
      console.log('ğŸ’¬ åˆ›å»ºç”¨æˆ·æ¶ˆæ¯:', userMessage);
      
      // 5. è°ƒç”¨LLMè·å–å›å¤
      chatHistoryRef.current.push({
        role: 'user',
        content: userText
      });
      console.log('ğŸ“š å½“å‰å¯¹è¯å†å²:', chatHistoryRef.current);

      console.log('ğŸ¤– å¼€å§‹LLMå¯¹è¯...');
      const chatResponse = await fetch('/api/chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          messages: chatHistoryRef.current
        })
      });

      if (!chatResponse.ok) {
        console.error('âŒ LLMå¯¹è¯è¯·æ±‚å¤±è´¥:', chatResponse.status, chatResponse.statusText);
        throw new Error('AIå¯¹è¯å¤±è´¥');
      }

      const chatResult = await chatResponse.json();
      console.log('ğŸ¯ LLMå¯¹è¯ç»“æœ:', chatResult);
      
      if (!chatResult.success) {
        console.error('âŒ LLMå¯¹è¯å¤±è´¥:', chatResult.error);
        throw new Error(chatResult.error || 'AIå¯¹è¯å¤±è´¥');
      }

      const aiText = chatResult.content;
      console.log('ğŸ¤– AIå›å¤å†…å®¹:', aiText);
      
      // 6. æ·»åŠ AIå›å¤æ¶ˆæ¯
      const aiMessage: VoiceMessage = {
        id: Date.now() + 1,
        content: aiText,
        isUser: false,
        timestamp: Date.now()
      };
      console.log('ğŸ¤– åˆ›å»ºAIæ¶ˆæ¯:', aiMessage);
      
      // æ›´æ–°æ¶ˆæ¯åˆ—è¡¨ - é‡è¦ï¼šåŸºäºå½“å‰å®Œæ•´å¯¹è¯è®°å½•æ·»åŠ æ–°æ¶ˆæ¯
      console.log('ğŸ“ æ›´æ–°æ¶ˆæ¯åˆ—è¡¨ï¼Œæ·»åŠ ç”¨æˆ·å’ŒAIæ¶ˆæ¯...');
      setMessages(currentMessages => {
        console.log('ğŸ”„ processAudioChunksä¸­çš„å½“å‰æ¶ˆæ¯çŠ¶æ€:', currentMessages);
        console.log('ğŸ“Š å½“å‰æ¶ˆæ¯åˆ—è¡¨é•¿åº¦:', currentMessages.length);
        const newMessages = [...currentMessages, userMessage, aiMessage];
        console.log('ğŸ“‹ æ–°çš„å®Œæ•´æ¶ˆæ¯åˆ—è¡¨:', newMessages);
        console.log('âœ… æ¶ˆæ¯æ›´æ–°å®Œæˆï¼Œæ–°é•¿åº¦:', newMessages.length);
        return newMessages;
      });
      
      chatHistoryRef.current.push({
        role: 'assistant',
        content: aiText
      });
      console.log('ğŸ“š æ›´æ–°åçš„å¯¹è¯å†å²:', chatHistoryRef.current);

      // æ¸…ç†éŸ³é¢‘æ•°æ®
      audioChunksRef.current = [];
      console.log('ğŸ§¹ éŸ³é¢‘æ•°æ®æ¸…ç†å®Œæˆ');

    } catch (error) {
      console.error('Process audio error:', error);
      throw error;
    }
  };

  const blobToBase64 = (blob: Blob): Promise<string> => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        const result = reader.result as string;
        resolve(result);
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  };

  // æ¸…ç†effect
  useEffect(() => {
    return () => {
      if (mediaRecorderRef.current) {
        mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  return {
    isRecording,
    isPaused,
    isConnected,
    error,
    isProcessing,
    messages,
    startRecording,
    stopRecording,
    pauseSession,
    resumeSession,
    endSession,
    clearError
  };
}